{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8694ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==3.1.0 in /home/akihito/.local/lib/python3.6/site-packages (3.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (2020.9.27)\n",
      "Requirement already satisfied: dataclasses in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (0.8)\n",
      "Requirement already satisfied: filelock in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (0.0.43)\n",
      "Requirement already satisfied: requests in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (0.8.1rc2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (0.1.91)\n",
      "Requirement already satisfied: numpy in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (4.50.0)\n",
      "Requirement already satisfied: packaging in /home/akihito/.local/lib/python3.6/site-packages (from transformers==3.1.0) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/akihito/.local/lib/python3.6/site-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/akihito/.local/lib/python3.6/site-packages (from requests->transformers==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/akihito/.local/lib/python3.6/site-packages (from requests->transformers==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/akihito/.local/lib/python3.6/site-packages (from requests->transformers==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/akihito/.local/lib/python3.6/site-packages (from requests->transformers==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click in /home/akihito/.local/lib/python3.6/site-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/akihito/.local/lib/python3.6/site-packages (from sacremoses->transformers==3.1.0) (0.17.0)\n",
      "Requirement already satisfied: six in /home/akihito/.local/lib/python3.6/site-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-di0q_8O1_QsOSEm1sIOQWvuSy2LTIYx\n",
      "To: /home/akihito/Desktop/TCC/bert_lex_ktrain_20201221.tar.gz\n",
      "526MB [01:30, 5.79MB/s] \n",
      "bert_lex_multilingual_small.model/\n",
      "bert_lex_multilingual_small.model/tf_model.preproc\n",
      "bert_lex_multilingual_small.model/tf_model.h5\n",
      "bert_lex_multilingual_small.model/config.json\n",
      "df_lex_embeddings.pickle\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/Vakihito/ktrain.git\n",
      "  Cloning https://github.com/Vakihito/ktrain.git to /tmp/pip-req-build-triy9oup\n",
      "  Running command git clone -q https://github.com/Vakihito/ktrain.git /tmp/pip-req-build-triy9oup\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.23.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (3.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (1.1.2)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (1.0.0)\n",
      "Requirement already satisfied: requests in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (2.25.1)\n",
      "Requirement already satisfied: joblib in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.17.0)\n",
      "Requirement already satisfied: packaging in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (20.9)\n",
      "Requirement already satisfied: ipython in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (7.16.1)\n",
      "Requirement already satisfied: langdetect in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (1.0.8)\n",
      "Requirement already satisfied: jieba in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.42.1)\n",
      "Requirement already satisfied: cchardet in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (2.1.6)\n",
      "Requirement already satisfied: syntok in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (1.3.1)\n",
      "Requirement already satisfied: seqeval==0.0.19 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.0.19)\n",
      "Requirement already satisfied: transformers<4.0,>=3.1.0 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (3.1.0)\n",
      "Requirement already satisfied: sentencepiece in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.1.91)\n",
      "Requirement already satisfied: keras_bert>=0.86.0 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (0.86.0)\n",
      "Requirement already satisfied: networkx>=2.3 in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (2.5)\n",
      "Requirement already satisfied: whoosh in /home/akihito/.local/lib/python3.6/site-packages (from ktrain==0.25.3) (2.7.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/akihito/.local/lib/python3.6/site-packages (from seqeval==0.0.19->ktrain==0.25.3) (1.19.5)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /home/akihito/.local/lib/python3.6/site-packages (from seqeval==0.0.19->ktrain==0.25.3) (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/akihito/.local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain==0.25.3) (1.5.2)\n",
      "Requirement already satisfied: h5py in /home/akihito/.local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain==0.25.3) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/akihito/.local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain==0.25.3) (5.3.1)\n",
      "Requirement already satisfied: keras-transformer>=0.38.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras_bert>=0.86.0->ktrain==0.25.3) (0.38.0)\n",
      "Requirement already satisfied: keras-pos-embd>=0.11.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.11.0)\n",
      "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.14.0)\n",
      "Requirement already satisfied: keras-multi-head>=0.27.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.27.0)\n",
      "Requirement already satisfied: keras-embed-sim>=0.8.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.8.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.6.0)\n",
      "Requirement already satisfied: keras-self-attention==0.46.0 in /home/akihito/.local/lib/python3.6/site-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras_bert>=0.86.0->ktrain==0.25.3) (0.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/akihito/.local/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain==0.25.3) (2021.5.30)\n",
      "Requirement already satisfied: six in /home/akihito/.local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain==0.25.3) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/akihito/.local/lib/python3.6/site-packages (from networkx>=2.3->ktrain==0.25.3) (5.0.9)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/akihito/.local/lib/python3.6/site-packages (from pandas>=1.0.1->ktrain==0.25.3) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/akihito/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->ktrain==0.25.3) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (0.8.1rc2)\n",
      "Requirement already satisfied: sacremoses in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (2020.9.27)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (4.50.0)\n",
      "Requirement already satisfied: dataclasses in /home/akihito/.local/lib/python3.6/site-packages (from transformers<4.0,>=3.1.0->ktrain==0.25.3) (0.8)\n",
      "Requirement already satisfied: cached-property in /home/akihito/.local/lib/python3.6/site-packages (from h5py->Keras>=2.2.4->seqeval==0.0.19->ktrain==0.25.3) (1.5.2)\n",
      "Requirement already satisfied: pexpect in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (0.18.0)\n",
      "Requirement already satisfied: backcall in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (57.0.0)\n",
      "Requirement already satisfied: pygments in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (2.9.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/akihito/.local/lib/python3.6/site-packages (from ipython->ktrain==0.25.3) (3.0.19)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/akihito/.local/lib/python3.6/site-packages (from jedi>=0.10->ipython->ktrain==0.25.3) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in /home/akihito/.local/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain==0.25.3) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /home/akihito/.local/lib/python3.6/site-packages (from traitlets>=4.2->ipython->ktrain==0.25.3) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/akihito/.local/lib/python3.6/site-packages (from pexpect->ipython->ktrain==0.25.3) (0.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/akihito/.local/lib/python3.6/site-packages (from requests->ktrain==0.25.3) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/akihito/.local/lib/python3.6/site-packages (from requests->ktrain==0.25.3) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/akihito/.local/lib/python3.6/site-packages (from requests->ktrain==0.25.3) (4.0.0)\n",
      "Requirement already satisfied: click in /home/akihito/.local/lib/python3.6/site-packages (from sacremoses->transformers<4.0,>=3.1.0->ktrain==0.25.3) (7.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytube in /home/akihito/.local/lib/python3.6/site-packages (10.8.5)\n",
      "Cloning into 'face_classification'...\n",
      "remote: Enumerating objects: 990, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 990 (delta 1), reused 0 (delta 0), pack-reused 984\u001b[K\n",
      "Receiving objects: 100% (990/990), 121.30 MiB | 1.18 MiB/s, done.\n",
      "Resolving deltas: 100% (554/554), done.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==3.1.0\n",
    "!gdown --id 1-di0q_8O1_QsOSEm1sIOQWvuSy2LTIYx\n",
    "!tar -xzvf bert_lex_ktrain_20201221.tar.gz\n",
    "!pip3 install git+https://github.com/Vakihito/ktrain.git\n",
    "!pip3 install pytube\n",
    "!git clone https://github.com/oarriaga/face_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28592dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feat_size = 112\n",
    "text_feat_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7251274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pytube import YouTube\n",
    "from pytube.helpers import safe_filename\n",
    "from statistics import mode\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "from face_classification.src.utils.datasets import get_labels\n",
    "from face_classification.src.utils.inference import detect_faces\n",
    "from face_classification.src.utils.inference import draw_text\n",
    "from face_classification.src.utils.inference import draw_bounding_box\n",
    "from face_classification.src.utils.inference import apply_offsets\n",
    "from face_classification.src.utils.inference import load_detection_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0377782",
   "metadata": {},
   "source": [
    "# Bert\n",
    "\n",
    "Carregando a modalidade de texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f5de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras import backend as K\n",
    "\n",
    "predictor_bert_lex = ktrain.load_predictor('bert_lex_multilingual_small.model')\n",
    "df_lex  = pickle.load(open('df_lex_embeddings.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8523912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>embedding</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>picketing</td>\n",
       "      <td>en</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.22929063, 0.15071137, -0.67776394, -0.17623...</td>\n",
       "      <td>0.95456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text lang  sentiment  \\\n",
       "2383  picketing   en         -1   \n",
       "\n",
       "                                              embedding    query  \n",
       "2383  [0.22929063, 0.15071137, -0.67776394, -0.17623...  0.95456  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(text,predictor):\n",
    "  tokenizer = predictor.preproc.get_tokenizer()\n",
    "  input_ids = tf.constant(tokenizer.encode(text))[None, :]  # Batch size 1\n",
    "  outputs = predictor.model.layers[0](input_ids)\n",
    "  last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "  v = np.average(last_hidden_states.numpy()[0],axis=0)\n",
    "  return v\n",
    "\n",
    "def get_bert_lex(text,k=3,min_query=0.8,use_predictor=False):\n",
    "  global df_lex, predictor_bert_lex\n",
    "\n",
    "  sentiment_model = predictor_bert_lex.predict(text)\n",
    "  features = get_embedding(text,predictor_bert_lex)\n",
    "  a = np.array([features])\n",
    "  b = np.array(list(df_lex['embedding']))\n",
    "  cos_sim = cosine_similarity(a,b)\n",
    "  df_lex['query'] = cos_sim[0]\n",
    "\n",
    "  temp = df_lex.sort_values(by='query',ascending=False).head(k)\n",
    "  if (temp.iloc[0]['query'] > min_query ):\n",
    "    temp = temp[temp['query'] > min_query]\n",
    "  sentiment_lex = np.average(np.array(temp['sentiment'].to_list()))\n",
    "  if use_predictor:\n",
    "    return temp, sentiment_lex, sentiment_model\n",
    "  return temp, sentiment_lex\n",
    "\n",
    "text= 'pessoas brigando na rua'\n",
    "df_explain, sentiment_lex = get_bert_lex(text,k=7)\n",
    "print(sentiment_lex)\n",
    "df_explain.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff7a13",
   "metadata": {},
   "source": [
    "# Caption\n",
    "\n",
    "Definindo algumas funções para tratamento das captions geradas pelo Pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af7c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the string time as HH:MM:SS and return in seconds\n",
    "def string_time_int(str_time):\n",
    "  segundos = int(str_time[-2:])\n",
    "  segundos += 60 * int(str_time[-5:-3])\n",
    "  segundos += 3600 * int(str_time[:-6])\n",
    "  return segundos\n",
    "def process_caption(video, lang='a.en'):\n",
    "  '''\n",
    "    extract the information from the caption and saves in a caption struct \n",
    "  '''\n",
    "  has_caption = False\n",
    "  print(video.captions)\n",
    "  for cap in video.captions:\n",
    "    if cap.code == lang:\n",
    "      has_caption = True\n",
    "\n",
    "  if not has_caption:\n",
    "    print(\"caption of lang : \" + lang + \" not found\")\n",
    "\n",
    "  video_len = video.length\n",
    "\n",
    "  captions  = video.captions[lang]\n",
    "  captions_str = str(captions.generate_srt_captions())\n",
    "  list_captions = []\n",
    "  line_counter = 1\n",
    "  for line in captions_str.split('\\n'):\n",
    "      # time type\n",
    "      if (line_counter + 2) % 4  == 0:\n",
    "          line_aux = line.split(\" --> \")\n",
    "          time_s = string_time_int(line_aux[0][:-4])\n",
    "          time_e = string_time_int(line_aux[1][:-4])\n",
    "      # comment type\n",
    "      if (line_counter + 1) % 4  == 0 and video_len >= time_e:  \n",
    "          list_captions.append([line, time_s, time_e])\n",
    "      line_counter += 1\n",
    "\n",
    "  return list_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd7d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    "\n",
    "def predict_text(text):\n",
    "    global predictor_bert_lex\n",
    "    polarity_text = predictor_bert_lex.predict(text)\n",
    "\n",
    "    color = np.asarray((255, 255, 255))\n",
    "\n",
    "    if polarity_text < -0.4:\n",
    "        color = abs(polarity_text) * np.asarray((255, 0, 0))\n",
    "    elif polarity_text > 0.4:\n",
    "        color = abs(polarity_text) * np.asarray((0, 255, 0))\n",
    "    \n",
    "    return color, polarity_text\n",
    "\n",
    "\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = './face_classification/trained_models/detection_models/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = './face_classification/trained_models/emotion_models/fer2013_mini_XCEPTION.51-0.63.hdf5'\n",
    "emotion_labels = get_labels('fer2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefcf33",
   "metadata": {},
   "source": [
    "# Carregando os modelos de imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97eab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models\n",
    "face_detection = load_detection_model(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "\n",
    "### gets the embedding from the emtion_classifier\n",
    "def getFaceEmbedding(gray_face,layer_out=3):\n",
    "  global emotion_classifier\n",
    "  inp = emotion_classifier.input\n",
    "\n",
    "  functor1 = K.function([inp], emotion_classifier.layers[-layer_out].output)\n",
    "  emotion_prediction = functor1([gray_face])[0]\n",
    "\n",
    "  return emotion_prediction.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f7f64f",
   "metadata": {},
   "source": [
    "# Fazendo download do vídeo\n",
    "Utilizamos o pytube para extrair a resolução do vídeo. Nesse sentido, os seguintes parâmetros são importante:\n",
    " - vid_id - é o id do vídeo do youtube que desejamos extrair\n",
    " - res - é a resulução do vídeo que desejamos extrair - creio que seja melhor manter 480, para o bom funcionamento das redes neurais\n",
    " - lang - é lingua da caption, indicaria utilizar 'en', mas caso queira utilizar legendas automáticas utilize 'a.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69dbab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading the video from the ulr :  https://www.youtube.com/watch?v=xiQ38WKoF2E\n",
      "135\n",
      "{'en': <Caption lang=\"English\" code=\"en\">, 'a.en': <Caption lang=\"English (auto-generated)\" code=\"a.en\">}\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters for bounding boxes shape\n",
    "frame_window = 10\n",
    "emotion_offsets = (20, 40)\n",
    "\n",
    "# getting input model shapes for inference\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "# starting lists for calculating modes\n",
    "emotion_window = []\n",
    "\n",
    "# starting video streaming\n",
    "\n",
    "vid_id = \"xiQ38WKoF2E\"\n",
    "res = 480\n",
    "lang = 'en'\n",
    "\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=\" + vid_id\n",
    "print(\"downloading the video from the ulr : \", url)\n",
    "video = YouTube(url)\n",
    "\n",
    "max_res = -1\n",
    "itag_max = -1\n",
    "\n",
    "fps_my = 30\n",
    "for stream in video.streams:\n",
    "    if stream.resolution and stream.mime_type == \"video/mp4\":\n",
    "      current_res = int(stream.resolution[:-1])\n",
    "      current_fps = int(stream.fps)\n",
    "      if current_res <= res and max_res < current_res:\n",
    "        max_res = current_res\n",
    "        itag_max = stream.itag\n",
    "        fps_my =  float(current_fps) \n",
    "\n",
    "if max_res == -1:\n",
    "  print(\"erro : chose another resolution\")\n",
    "\n",
    "font_scale_cur = max_res/144\n",
    "\n",
    "print(str(itag_max))\n",
    "video.streams.get_by_itag(str(itag_max)).download()\n",
    "\n",
    "dirname = './'\n",
    "video_path = os.path.join(dirname, safe_filename(video.title) + '.mp4')\n",
    "\n",
    "\n",
    "#documentation: https://pypi.org/project/pafy/\n",
    "# video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "captions_list = process_caption(video,'en')\n",
    "captions_list.sort(key=lambda x: x[1])\n",
    "\n",
    "\n",
    "time = 0\n",
    "frame_counter = 0\n",
    "caption_counter = 0\n",
    "\n",
    "video_frequency = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2e7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo certos caracteres da caption\n",
    "for i in range(len(captions_list)):\n",
    "  captions_list[i][0] = captions_list[i][0].replace(u'\\xa0', u' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a3639b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo um dicionario que relacionará os valores\n",
    "video_dict_all = {\n",
    "    'frame' : [],\n",
    "    'time' : [],\n",
    "    'caption' : [],\n",
    "    'caption_polarity' : [],\n",
    "    'caption_emb' : [],\n",
    "    'face' : [],\n",
    "    'face_polarity' : [],\n",
    "    'face_emb' : []\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f2cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dict(frame,time,\n",
    "              caption, caption_polarity, caption_emb,\n",
    "              face, face_polarity, face_emb):\n",
    "  video_df_all = {\n",
    "    'frame' : [frame],\n",
    "    'time' : [time],\n",
    "    'caption' : caption,\n",
    "    'caption_polarity' : caption_polarity,\n",
    "    'caption_emb' : caption_emb,\n",
    "    'face' : face,\n",
    "    'face_polarity' : face_polarity,\n",
    "    'face_emb' : face_emb\n",
    "  }\n",
    "\n",
    "  if len(caption) == 0:\n",
    "    video_df_all['caption'] = ['-1']\n",
    "    video_df_all['caption_polarity'] = [0]\n",
    "    video_df_all['caption_emb'] = [np.zeros(text_feat_size)]\n",
    "\n",
    "  if len(face) == 0:\n",
    "    video_df_all['face'] = ['-1']\n",
    "    video_df_all['face_polarity'] = [0]\n",
    "    video_df_all['face_emb'] = [np.zeros(img_feat_size)]\n",
    "  \n",
    "  if len(face) >= 2:\n",
    "    for i in range(len(face) - 1):\n",
    "      video_df_all['frame'].append(video_df_all['frame'][-1])\n",
    "      video_df_all['time'].append(video_df_all['time'][-1])\n",
    "      video_df_all['caption'].append(video_df_all['caption'][-1])\n",
    "      video_df_all['caption_polarity'].append(video_df_all['caption_polarity'][-1])\n",
    "      video_df_all['caption_emb'].append(video_df_all['caption_emb'][-1])\n",
    "\n",
    "  return video_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572badf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_list_size = len(captions_list)\n",
    "\n",
    "def return_text(time, counter):\n",
    "  temp_text = \"\"\n",
    "  for i in range(counter, captions_list_size):\n",
    "    if time >= captions_list[i][1] and time <= captions_list[caption_counter][2]:\n",
    "      temp_text +=  captions_list[i][0] + \" \"\n",
    "    elif captions_list[i][1] > time:\n",
    "      return  temp_text\n",
    "  return temp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54acce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3985b",
   "metadata": {},
   "source": [
    "# Loop de processamento\n",
    "Neste loop processamos o vídeo através dos modelos unimodais\n",
    " - frame_limit - o limite de frames a serem analizados, caso queira analizar todos os frames coloque inf.\n",
    " - size_shape - formato da imagem a ser gerada\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f91a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  1\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  2\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  3\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  4\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  5\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  6\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  7\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  8\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  9\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  10\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  11\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  12\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  13\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  14\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  15\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  16\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  17\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  18\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  19\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  20\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  21\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "you shall not pass\n",
      "fc :  22\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  23\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  24\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  25\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  26\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  27\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  28\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  29\n",
      "##################################################\n",
      "caption polarity: [0.7204882]\n",
      "caption sentence: Today we are going to \n",
      "face polarity:  0.0 neutral\n",
      "fc :  30\n",
      "##################################################\n",
      "caption polarity: [0.6081896]\n",
      "caption sentence: Today we are going to  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  31\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  32\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  33\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  34\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face not found !\n",
      "fc :  35\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  36\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  37\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  38\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  39\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  40\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  41\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  42\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  43\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  44\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  45\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  46\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  47\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  48\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  49\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  50\n",
      "##################################################\n",
      "caption polarity: [0.25682622]\n",
      "caption sentence:  show you guys \n",
      "face polarity:  0.0 neutral\n",
      "fc :  51\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "frame_limit = 50\n",
    "size_shape = ( 240 , 320 )\n",
    "cv2.namedWindow('window_frame')\n",
    "img_counter = 0\n",
    "time = 0\n",
    "frame_counter = 0\n",
    "caption_counter = 0\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Coordenadas \n",
    "# 1 - distancia da borda lateral esquerda \n",
    "# 2 - distancia da borda superior \n",
    "#\n",
    "\n",
    "while True:\n",
    "    success , bgr_image = video_capture.read()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"fim !\")\n",
    "        break\n",
    "      \n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    faces = detect_faces(face_detection, gray_image)\n",
    "\n",
    "    time = frame_counter/fps_my \n",
    "\n",
    "\n",
    "    caption = []\n",
    "    caption_polarity = []\n",
    "    caption_emb = []\n",
    "\n",
    "    cur_text = return_text(time, caption_counter)\n",
    "    if len(cur_text) > 0:\n",
    "        color_caption, caption_polarity = predict_text(cur_text)\n",
    "        caption = [cur_text]\n",
    "        caption_polarity = [caption_polarity]\n",
    "        caption_emb = [get_embedding(cur_text,predictor_bert_lex)]\n",
    "        if frame_counter % video_frequency == 0:\n",
    "        \n",
    "          print(\"caption polarity:\", caption_polarity)\n",
    "          print(\"caption sentence:\", cur_text)\n",
    "\n",
    "        color_caption = color_caption.tolist()\n",
    "        draw_text(np.array([10,max_res - 30,50,50]), rgb_image, cur_text,color_caption,font_scale=0.4, thickness=1)\n",
    "        while caption_counter < len(captions_list) - 1 and time >= captions_list[caption_counter][2]:  \n",
    "            caption_counter += 1\n",
    "\n",
    "    face = []\n",
    "    face_polarity = []\n",
    "    face_emb = []\n",
    "    if len(faces) == 0 :\n",
    "      print(\"face not found !\")\n",
    "\n",
    "    for face_coordinates in faces:\n",
    "\n",
    "        x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "\n",
    "        gray_face = gray_image[y1:y2, x1:x2]\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except cv2.error:\n",
    "            print('error : on resize')\n",
    "            continue\n",
    "\n",
    "        gray_face = my_preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        gray_face = np.expand_dims(gray_face, -1)\n",
    "\n",
    "        emotion_prediction = emotion_classifier.predict(gray_face)\n",
    "        emotion_probability = np.max(emotion_prediction)\n",
    "        emotion_label_arg = np.argmax(emotion_prediction)\n",
    "\n",
    "        emotion_text = emotion_labels[emotion_label_arg]\n",
    "        emotion_window.append(emotion_text)\n",
    "\n",
    "        if len(emotion_window) > frame_window:\n",
    "            emotion_window.pop(0)\n",
    "        try:\n",
    "            emotion_mode = mode(emotion_window)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        ### threshold wall\n",
    "        # ysnp = you shall not pass\n",
    "        ysnp = False\n",
    "        sentiment = 'neutral'\n",
    "        if emotion_text == 'angry' and emotion_probability >= 0.5:\n",
    "            ysnp = True\n",
    "            sentiment = 'negative'\n",
    "        if emotion_text == 'happy' and emotion_probability >= 0.7:\n",
    "            ysnp = True\n",
    "            sentiment = 'positive'\n",
    "        if emotion_text == 'sad' and emotion_probability >= 0.45:\n",
    "            ysnp = True\n",
    "            sentiment = 'negative'\n",
    "        if emotion_text == 'neutral' and emotion_probability >= 0.5:\n",
    "            ysnp = True\n",
    "            sentiment = 'neutral'\n",
    "        if emotion_text == 'fear' and emotion_probability >= 0.5:\n",
    "            ysnp = True\n",
    "            sentiment = 'negative'\n",
    "        if emotion_text == 'surprise' and emotion_probability >= 0.4:\n",
    "            ysnp = True\n",
    "            sentiment = 'positive'\n",
    "\n",
    "        if ysnp:\n",
    "            senti_multi = 0\n",
    "            if sentiment == 'negative':\n",
    "                senti_multi = -1\n",
    "                color = emotion_probability * np.asarray((255, 0, 0))\n",
    "            elif sentiment == 'positive':\n",
    "                senti_multi = 1\n",
    "                color = emotion_probability * np.asarray((0, 255, 0))\n",
    "            else:\n",
    "                senti_multi = 0\n",
    "                color = emotion_probability * np.asarray((0, 0, 255))\n",
    "\n",
    "            color = color.astype(int)\n",
    "            color = color.tolist()\n",
    "\n",
    "            draw_bounding_box(face_coordinates, rgb_image, color)\n",
    "            draw_text(face_coordinates, rgb_image, sentiment,color, 0, -45, 1, 1)\n",
    "            if frame_counter % video_frequency == 0:\n",
    "              print('face polarity: ', emotion_probability * senti_multi,emotion_text)\n",
    "\n",
    "\n",
    "            face.append('img' + str(img_counter))\n",
    "            face_polarity.append(emotion_probability * senti_multi)\n",
    "            face_emb.append(getFaceEmbedding(gray_face) )\n",
    "\n",
    "            img_counter += 1\n",
    "        elif frame_counter % video_frequency == 0:\n",
    "            print(\"you shall not pass\")\n",
    "\n",
    "   \n",
    "    dict_temp= fill_dict(frame_counter, time,\n",
    "                        caption, caption_polarity, caption_emb,\n",
    "                        face, face_polarity, face_emb)       \n",
    "    for key in dict_temp.keys():\n",
    "      video_dict_all[key] += dict_temp[key]\n",
    "    \n",
    "    frame_counter += 1\n",
    "\n",
    "  # if len(cur_text) > 0:\n",
    "\n",
    "#     if frame_counter % video_frequency == 0:\n",
    "        \n",
    "    print(\"fc : \",frame_counter)\n",
    "    resized = cv2.resize(rgb_image, size_shape)\n",
    "    bgr_image = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('window_frame', bgr_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    print(\"#\" * 50)\n",
    "    if(frame_counter > frame_limit):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64128f49",
   "metadata": {},
   "source": [
    "# Correlação entre caption e text\n",
    " - time  - mostra o tempo em segundos de início da análise\n",
    " - frame - mostra o frame sobre análise\n",
    " - caption - mostra a legenda mostrada\n",
    " - caption_polarity - mostra a polaridade da caption\n",
    " - caption_emb - mostra a embedding gerada pelo Bert\n",
    " - face - mostra um couter referente a imagem\n",
    " - face_polarity - mostra a polaridade da face\n",
    " - face_emb - mostra a embedding gerada pelo modelo de faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9128c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>time</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_polarity</th>\n",
       "      <th>caption_emb</th>\n",
       "      <th>face</th>\n",
       "      <th>face_polarity</th>\n",
       "      <th>face_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.9817237, -7.3088036, -0.21659227, 1.669573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-2.35278, -7.1067867, -0.80641127, 3.150189, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.0932013, -4.5289273, 1.1658401, 1.031141, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-4.0827923, -7.5882707, -0.90062743, 3.067546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-2.856795, -5.6585393, 0.58233565, 1.700731, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame      time                 caption  caption_polarity  \\\n",
       "0      0  0.000000  Today we are going to           0.720488   \n",
       "1      1  0.033333  Today we are going to           0.720488   \n",
       "2      2  0.066667  Today we are going to           0.720488   \n",
       "3      3  0.100000  Today we are going to           0.720488   \n",
       "4      4  0.133333  Today we are going to           0.720488   \n",
       "\n",
       "                                         caption_emb  face  face_polarity  \\\n",
       "0  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img0            0.0   \n",
       "1  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img1            0.0   \n",
       "2  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img2            0.0   \n",
       "3  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img3            0.0   \n",
       "4  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img4            0.0   \n",
       "\n",
       "                                            face_emb  \n",
       "0  [-1.9817237, -7.3088036, -0.21659227, 1.669573...  \n",
       "1  [-2.35278, -7.1067867, -0.80641127, 3.150189, ...  \n",
       "2  [-1.0932013, -4.5289273, 1.1658401, 1.031141, ...  \n",
       "3  [-4.0827923, -7.5882707, -0.90062743, 3.067546...  \n",
       "4  [-2.856795, -5.6585393, 0.58233565, 1.700731, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "video_df = pd.DataFrame(video_dict_all)\n",
    "\n",
    "video_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19af667",
   "metadata": {},
   "source": [
    "# Gerando concordância entre modelos\n",
    "Neste passo preparamos o modelo para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17459b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concord_bool(a,b):\n",
    "  multi = a * b\n",
    "  if multi >= 0:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def concord_val(a,b):\n",
    "  (pa , pb) = (a,b)\n",
    "  if abs(a) < 0.3:\n",
    "    pa = 0\n",
    "  if abs(b) < 0.3:\n",
    "    pb = 0\n",
    "  multi = pa * pb\n",
    "  if multi >= 0:\n",
    "    if pa < 0 or pb < 0:\n",
    "      return 'negative'\n",
    "    if pa > 0 or pb > 0:\n",
    "      return 'positive'\n",
    "  return 'neutral'\n",
    "\n",
    "def return_dict():\n",
    "  dict_aux = {\n",
    "    'frame' : [],\n",
    "    'time' : [],\n",
    "    'caption' : [],\n",
    "    'caption_polarity' : [],\n",
    "    'caption_emb' : [],\n",
    "    'face' : [],\n",
    "    'face_polarity' : [],\n",
    "    'face_emb' : [],\n",
    "    'intent' : []\n",
    "  }\n",
    "  return dict_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27d5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concord_embedding():\n",
    "  global video_df\n",
    "  couter = 0\n",
    "  df_train = return_dict()\n",
    "  df_test = return_dict()\n",
    "  concord = []\n",
    "  for i , row in video_df.iterrows():\n",
    "    if concord_bool(row['face_polarity'],row['caption_polarity']):\n",
    "      for key in row.keys():\n",
    "        df_train[key].append(row[key])\n",
    "      df_train['intent'].append(concord_val(row['face_polarity'],row['caption_polarity']))\n",
    "      concord.append(1)\n",
    "    else:\n",
    "      for key in row.keys():\n",
    "        df_test[key].append(row[key])\n",
    "      df_test['intent'].append(concord_val(row['face_polarity'],row['caption_polarity']))\n",
    "      concord.append(0)\n",
    "  video_df['consent'] = concord\n",
    "  return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0914501",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train, df_test) =  get_concord_embedding()\n",
    "df_train = pd.DataFrame(df_train)\n",
    "df_test = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d386cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "class acc_callback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2635b",
   "metadata": {},
   "source": [
    "# Definindo um modelo\n",
    "Para esta aplicação definimos um modelo de atenção em relação a modalidade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cde6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dot,Activation,Dense, Input, concatenate, multiply, average, subtract, add, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def multimodal_text_image(num_classes,size_1=img_feat_size,size_2=text_feat_size,operator='att',verbose=0):\n",
    "\n",
    "  # fusion_dim = X_1.shape[1]+X_2.shape[1]\n",
    "  fusion_dim = size_1\n",
    "\n",
    "  inp1 = Input(shape=size_1)\n",
    "  inp2 = Input(shape=size_2)\n",
    "\n",
    "  l1 = Dense(fusion_dim, activation='relu')(inp1)\n",
    "  l2 = Dense(fusion_dim, activation='relu')(inp2)\n",
    "\n",
    "  if(operator=='att'):\n",
    "    visual_embd = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l1) # (bs, ndim)\n",
    "    average_seq = Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1))(l2) # (bs, ndim)\n",
    "    scalar_visual = Dense(1)(visual_embd) # (bs, 1)\n",
    "    scalar_text = Dense(1)(average_seq) # (bs, 1)\n",
    "    scalars = concatenate([scalar_visual, scalar_text], name='concat')  # (bs, 2)\n",
    "\n",
    "    # # Step 2. Normalize weights - softmax\n",
    "    alphas = Activation('softmax')(scalars) # (bs, 2)\n",
    "\n",
    "    # Step 3. Weighted average\n",
    "    visual_embd_2 = Lambda( lambda x: tf.keras.backend.expand_dims(x) ) (visual_embd) # (bs, ndim, 1)\n",
    "    average_seq_2 = Lambda( lambda x: tf.keras.backend.expand_dims(x) )(average_seq) # (bs, ndim, 1)\n",
    "    features = concatenate([visual_embd_2, average_seq_2], name='concat_feats') # (bs, ndim, 2)\n",
    "    w = Dot(axes=[-1, -1])([alphas, features]) # (bs, ndim)\n",
    "\n",
    "  w = Dropout(0.5)(w)\n",
    "  # fusion_layer = Dense(fusion_dim, activation='relu')(w)\n",
    "  fusion_layer = w\n",
    "\n",
    "  if (operator == 'att_labels'): # nm: new\n",
    "    output = Dense(1)(fusion_layer)  # (batch_size, nb_labels, 1)  \n",
    "    output = Lambda(lambda x: tf.keras.backend.squeeze(x, axis=-1))(output)  # (batch_size, nb_labels)\n",
    "    output = Activation('softmax')(output)  # (batch_size, nb_labels)    \n",
    "  else:\n",
    "    output = Dense(num_classes,activation='softmax')(fusion_layer)\n",
    "\n",
    "  model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "  model.summary()\n",
    "\n",
    "  return model, fusion_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ecd144",
   "metadata": {},
   "source": [
    "# Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df03d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 112)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 768)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 112)          12656       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 112)          86128       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 112)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 112)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            113         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            113         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 112, 1)       0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 112, 1)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2)            0           concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_feats (Concatenate)      (None, 112, 2)       0           lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 112)          0           activation_16[0][0]              \n",
      "                                                                 concat_feats[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 112)          0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            226         dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 99,236\n",
      "Trainable params: 99,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 0.6434\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4938\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4312\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3858\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3946\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3424\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3578\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3503\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3172\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3201\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2900\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2905\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2814\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2607\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2878\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2524\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2473\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2454\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2310\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2164\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2292\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2493\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2133\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2048\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2101\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1946\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1910\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1824\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1674\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1938\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1720\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1828\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1703\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1851\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1563\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1478\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1481\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1459\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1481\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1335\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1484\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1410\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1463\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1360\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1221\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1289\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1289\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1070\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1273\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "target = 'intent'\n",
    "\n",
    "merging_layers = ['autoencoder', 'att_labels','att','concatenate','add','subtract','average','multiply']\n",
    "\n",
    "num_classes = len(df_train[target].unique())\n",
    "operator = \"att\"\n",
    "# Gerando os modelos\n",
    "my_model, _ = multimodal_text_image(num_classes,operator=operator)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# merging_layers = ['att', 'att_labels'] # test\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "(df_data_train, df_data_test) = (df_train, df_test)\n",
    "\n",
    "total_rows = len(df_data_train[target])\n",
    "\n",
    "# modalidade da imagem\n",
    "X_1 = np.array(df_data_train['face_emb'].to_list())\n",
    "# modalidade do texto\n",
    "X_2 = np.array(df_data_train['caption_emb'].to_list())\n",
    "\n",
    "Y = np.array(pd.get_dummies(df_data_train[target]))\n",
    "\n",
    "num_classes = len(df_data_train[target].unique())\n",
    "\n",
    "# modalidades imagem e texto do teste\n",
    "X_1_test = np.array(df_data_test['face_emb'].to_list())\n",
    "X_2_test = np.array(df_data_test['caption_emb'].to_list())\n",
    "\n",
    "acc_call = acc_callback()\n",
    "\n",
    "\n",
    "history = my_model.fit([X_1,X_2], Y,\n",
    "                  epochs=50,\n",
    "                  batch_size=16,\n",
    "                  shuffle=True,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f3ab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mnot a single contradiction between the unmodal models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([])\n",
    "if len(X_1_test) > 0:\n",
    "  probs = my_model.predict([X_1_test,X_2_test])\n",
    "  y_pred = np.argmax(probs,axis=1)\n",
    "  print(\"size, test case : \", len(X_1_test))\n",
    "else:\n",
    "  print(\"\\033[93mnot a single contradiction between the unmodal models\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "082210db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_y_pred = {\n",
    "    0 : 'negative', \n",
    "    1 : 'neutral',\n",
    "    2 : 'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37e0ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_value = [dict_y_pred[pred] for pred in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25a46738",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = video_df[video_df['consent'] == 0].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3961cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_value_size = len(y_pred_value)\n",
    "\n",
    "tuple_idx_val = []\n",
    "\n",
    "for i in range(y_pred_value_size):\n",
    "  tuple_idx_val.append((index[i], y_pred_value[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a1d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_consent_df = video_df[video_df['consent'] == 1]\n",
    "\n",
    "for idx, row in video_consent_df.iterrows():\n",
    "  tuple_idx_val.append((idx, concord_val(row['caption_polarity'],row['face_polarity']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b699f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_idx_val.sort(key=lambda x:x[0])\n",
    "final_pred = [i[1] for i in tuple_idx_val]\n",
    "\n",
    "\n",
    "video_df['final_pred'] = final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c532bc7",
   "metadata": {},
   "source": [
    "# Resultados do modelo multimodal\n",
    " - consent - consentimento entre modelo de faces e de texto - 1 - verdadeiro, 0 - falso \n",
    " - final_pred - previsão final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27f4a065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>time</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_polarity</th>\n",
       "      <th>caption_emb</th>\n",
       "      <th>face</th>\n",
       "      <th>face_polarity</th>\n",
       "      <th>face_emb</th>\n",
       "      <th>consent</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.9817237, -7.3088036, -0.21659227, 1.669573...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-2.35278, -7.1067867, -0.80641127, 3.150189, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1.0932013, -4.5289273, 1.1658401, 1.031141, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-4.0827923, -7.5882707, -0.90062743, 3.067546...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>Today we are going to</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>[0.1871648, -0.08017133, 0.8622961, -0.1523684...</td>\n",
       "      <td>img4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-2.856795, -5.6585393, 0.58233565, 1.700731, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame      time                 caption  caption_polarity  \\\n",
       "0      0  0.000000  Today we are going to           0.720488   \n",
       "1      1  0.033333  Today we are going to           0.720488   \n",
       "2      2  0.066667  Today we are going to           0.720488   \n",
       "3      3  0.100000  Today we are going to           0.720488   \n",
       "4      4  0.133333  Today we are going to           0.720488   \n",
       "\n",
       "                                         caption_emb  face  face_polarity  \\\n",
       "0  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img0            0.0   \n",
       "1  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img1            0.0   \n",
       "2  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img2            0.0   \n",
       "3  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img3            0.0   \n",
       "4  [0.1871648, -0.08017133, 0.8622961, -0.1523684...  img4            0.0   \n",
       "\n",
       "                                            face_emb  consent final_pred  \n",
       "0  [-1.9817237, -7.3088036, -0.21659227, 1.669573...        1   positive  \n",
       "1  [-2.35278, -7.1067867, -0.80641127, 3.150189, ...        1   positive  \n",
       "2  [-1.0932013, -4.5289273, 1.1658401, 1.031141, ...        1   positive  \n",
       "3  [-4.0827923, -7.5882707, -0.90062743, 3.067546...        1   positive  \n",
       "4  [-2.856795, -5.6585393, 0.58233565, 1.700731, ...        1   positive  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "140c6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plus_sign(img, center=(10,10) ):\n",
    "  start_point = (center[0] - 5, center[1] - 2)\n",
    "  end_point = (center[0] + 5, center[1] + 2)\n",
    "  img_r = cv2.rectangle(img, start_point, end_point, (0,255,0), -1)\n",
    "\n",
    "  start_point = (center[0] - 2, center[1] - 5)\n",
    "  end_point = (center[0] + 2, center[1] + 5)\n",
    "  img_r = cv2.rectangle(img_r, start_point, end_point, (0,255,0), -1)\n",
    "\n",
    "  return img_r\n",
    "\n",
    "def draw_minus_sign(img, center=(10,10)):\n",
    "  start_point = (center[0] - 5, center[1] - 2)\n",
    "  end_point = (center[0] + 5, center[1] + 2)\n",
    "  img_r = cv2.rectangle(img, start_point, end_point, (255,0,0), -1)\n",
    "\n",
    "  return img_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f1f7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr =video_df['time'].to_list()\n",
    "final_pred_arr = video_df['final_pred'].to_list()\n",
    "size_total = len(time_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0d8de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_time_pred = [(time_arr[i], final_pred_arr[i]) for i in range(size_total)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d666ee",
   "metadata": {},
   "source": [
    "# Mostrando o resultado do modelo multimodal na janela\n",
    " - sinal positivo significa que a seção apresentou um polaridade positiva\n",
    " - sinal negativo significa que a seção apresentou um polaridade negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d92029df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### re inicializando as variáveis.\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "time = 0\n",
    "frame_counter = 0\n",
    "caption_counter = 0\n",
    "counter_tuple_total = 0 \n",
    "sentiment_polarity = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59a9beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc :  1\n",
      "positive\n",
      "##################################################\n",
      "fc :  2\n",
      "positive\n",
      "##################################################\n",
      "fc :  3\n",
      "positive\n",
      "##################################################\n",
      "fc :  4\n",
      "positive\n",
      "##################################################\n",
      "fc :  5\n",
      "positive\n",
      "##################################################\n",
      "fc :  6\n",
      "positive\n",
      "##################################################\n",
      "fc :  7\n",
      "positive\n",
      "##################################################\n",
      "fc :  8\n",
      "positive\n",
      "##################################################\n",
      "fc :  9\n",
      "positive\n",
      "##################################################\n",
      "fc :  10\n",
      "positive\n",
      "##################################################\n",
      "fc :  11\n",
      "positive\n",
      "##################################################\n",
      "fc :  12\n",
      "positive\n",
      "##################################################\n",
      "fc :  13\n",
      "positive\n",
      "##################################################\n",
      "fc :  14\n",
      "positive\n",
      "##################################################\n",
      "fc :  15\n",
      "positive\n",
      "##################################################\n",
      "fc :  16\n",
      "positive\n",
      "##################################################\n",
      "fc :  17\n",
      "positive\n",
      "##################################################\n",
      "fc :  18\n",
      "positive\n",
      "##################################################\n",
      "fc :  19\n",
      "positive\n",
      "##################################################\n",
      "fc :  20\n",
      "positive\n",
      "##################################################\n",
      "fc :  21\n",
      "positive\n",
      "##################################################\n",
      "fc :  22\n",
      "positive\n",
      "##################################################\n",
      "fc :  23\n",
      "positive\n",
      "##################################################\n",
      "fc :  24\n",
      "positive\n",
      "##################################################\n",
      "fc :  25\n",
      "positive\n",
      "##################################################\n",
      "fc :  26\n",
      "positive\n",
      "##################################################\n",
      "fc :  27\n",
      "positive\n",
      "##################################################\n",
      "fc :  28\n",
      "positive\n",
      "##################################################\n",
      "fc :  29\n",
      "positive\n",
      "##################################################\n",
      "fc :  30\n",
      "positive\n",
      "##################################################\n",
      "fc :  31\n",
      "positive\n",
      "##################################################\n",
      "fc :  32\n",
      "positive\n",
      "##################################################\n",
      "fc :  33\n",
      "neutral\n",
      "##################################################\n",
      "fc :  34\n",
      "neutral\n",
      "##################################################\n",
      "fc :  35\n",
      "neutral\n",
      "##################################################\n",
      "fc :  36\n",
      "neutral\n",
      "##################################################\n",
      "fc :  37\n",
      "neutral\n",
      "##################################################\n",
      "fc :  38\n",
      "neutral\n",
      "##################################################\n",
      "fc :  39\n",
      "neutral\n",
      "##################################################\n",
      "fc :  40\n",
      "neutral\n",
      "##################################################\n",
      "fc :  41\n",
      "neutral\n",
      "##################################################\n",
      "fc :  42\n",
      "neutral\n",
      "##################################################\n",
      "fc :  43\n",
      "neutral\n",
      "##################################################\n",
      "fc :  44\n",
      "neutral\n",
      "##################################################\n",
      "fc :  45\n",
      "neutral\n",
      "##################################################\n",
      "fc :  46\n",
      "neutral\n",
      "##################################################\n",
      "fc :  47\n",
      "neutral\n",
      "##################################################\n",
      "fc :  48\n",
      "neutral\n",
      "##################################################\n",
      "fc :  49\n",
      "neutral\n",
      "##################################################\n",
      "fc :  50\n",
      "neutral\n",
      "##################################################\n",
      "fc :  51\n",
      "neutral\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success , bgr_image = video_capture.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    time = frame_counter/fps_my \n",
    "\n",
    "\n",
    "\n",
    "    if time >= captions_list[caption_counter][1] and time <= captions_list[caption_counter][2]:\n",
    "        color_caption = (255,255,255)\n",
    "        draw_text(np.array([10,max_res - 30,50,50]), rgb_image, cur_text,color_caption,font_scale=0.4, thickness=1)\n",
    "\n",
    "        if caption_counter < len(captions_list) - 1 and time >= captions_list[caption_counter + 1][1]:  \n",
    "            caption_counter += 1\n",
    "    \n",
    "    if time >= tuple_time_pred[counter_tuple_total][0]:\n",
    "        sentiment_polarity = tuple_time_pred[counter_tuple_total][1]\n",
    "        if (tuple_time_pred[counter_tuple_total][1] == 'positive') :\n",
    "          rgb_image = draw_plus_sign(rgb_image)\n",
    "        elif (tuple_time_pred[counter_tuple_total][1] == 'negative'):\n",
    "          rgb_image = draw_minus_sign(rgb_image)\n",
    "\n",
    "        if counter_tuple_total < len(tuple_time_pred) - 1 and time >= tuple_time_pred[counter_tuple_total + 1][0]:  \n",
    "            counter_tuple_total += 1\n",
    "    \n",
    "    \n",
    "    frame_counter += 1\n",
    "    \n",
    "  \n",
    "    print(\"fc : \",frame_counter)\n",
    "    print(sentiment_polarity)\n",
    "    resized = cv2.resize(rgb_image, size_shape)\n",
    "    bgr_image = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('window_frame', bgr_image)\n",
    "    if cv2.waitKey(33) & 0xFF == ord('q'):\n",
    "        break\n",
    "    print(\"#\" * 50)\n",
    "    if(frame_counter > frame_limit):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a715b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
